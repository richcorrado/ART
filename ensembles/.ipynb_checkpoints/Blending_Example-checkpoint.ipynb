{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blending Regression on the Kaggle Housing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Richard Corrado richcorrado.github.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data files are stored in the same github directory as this notebook.  For the purposes of this exercise, we won't go into too many details of the datasets.  They were all generated from the same messy data set, but after EDA and feature engineering in R, choice and defintion of new features evolved. However many tidy data files were generated as saved during the learning process.  They have many features in common, but have important differences.\n",
    "\n",
    "In this notebook, we will pick one dataset and use 6 models to make predictions on the test set.  We will use a weighted average of the individual predictions to produce the blended prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.precision',5)\n",
    "from scipy import stats\n",
    "from scipy import optimize\n",
    "\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from xgboost.training import train\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "import matplotlib\n",
    "# this is needed for interactive plots to be displayed properly\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "from matplotlib import pyplot\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "# allow interactive plots\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def to compare goodness of fit on training set\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set size:', (1451, 390))\n",
      "('Test set size:', (1459, 390))\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train-1-9-delout.csv\")\n",
    "test_df = pd.read_csv(\"test-1-9-delout.csv\")\n",
    "\n",
    "# Set up predictors and response\n",
    "y_train = train_df['LogSalePrice'].values\n",
    "x_train = train_df.drop(['Id','LogSalePrice'],axis=1).values\n",
    "x_test = test_df.drop(['Id'],axis=1).values\n",
    "\n",
    "print(\"Training set size:\", x_train.shape)\n",
    "print(\"Test set size:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fit the models on the training data and obtain the training errors.  The training errors will then be used to define the weights for the averaging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge score on training set: 0.090990\n"
     ]
    }
   ],
   "source": [
    "ridge_regr = linear_model.Ridge(alpha = 55)\n",
    "ridge_regr.fit(x_train, y_train)\n",
    "\n",
    "y_ridge_pred = ridge_regr.predict(x_train)\n",
    "rmse_ridge = rmse(y_train, y_ridge_pred)\n",
    "print(\"Ridge score on training set: %f\" % rmse_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso score on training set: 0.092526\n"
     ]
    }
   ],
   "source": [
    "lasso_regr = linear_model.Lasso(alpha=0.0006, max_iter=50000)\n",
    "lasso_regr.fit(x_train, y_train)\n",
    "\n",
    "y_lasso_pred = lasso_regr.predict(x_train)\n",
    "rmse_lasso = rmse(y_train, y_lasso_pred)\n",
    "print(\"Lasso score on training set: %f\" % rmse_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elastic Net score on training set: 0.092101\n"
     ]
    }
   ],
   "source": [
    "elnet_regr = linear_model.ElasticNet(alpha = 0.0011, l1_ratio=0.5, max_iter=15000, random_state=7)\n",
    "elnet_regr.fit(x_train, y_train)\n",
    "\n",
    "y_elnet_pred = elnet_regr.predict(x_train)\n",
    "rmse_elnet = rmse(y_train, y_elnet_pred)\n",
    "print(\"Elastic Net score on training set: %f\" % rmse_elnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest score on training set: 0.046494\n"
     ]
    }
   ],
   "source": [
    "rf_regr = RandomForestRegressor(n_estimators = 700, max_depth = 25, random_state = 7)\n",
    "rf_regr.fit(x_train, y_train)\n",
    "\n",
    "y_rf_pred = rf_regr.predict(x_train)\n",
    "rmse_rf = rmse(y_train, y_rf_pred)\n",
    "print(\"Random Forest score on training set: %f\" % rmse_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regressor score on training set: 0.080296\n"
     ]
    }
   ],
   "source": [
    "svm_regr = svm.SVR(C=5, cache_size=200, coef0=0.0, degree=3, epsilon=0.034, gamma=0.0004,\n",
    "                        kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
    "svm_regr.fit(x_train, y_train)\n",
    "\n",
    "y_svm_pred = svm_regr.predict(x_train)\n",
    "rmse_svm = rmse(y_train, y_svm_pred)\n",
    "print(\"Support Vector Regressor score on training set: %f\" % rmse_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Regressor score on training set: 0.084155\n"
     ]
    }
   ],
   "source": [
    "xgb_regr = xgb.XGBRegressor(\n",
    "    max_depth = 1,\n",
    "    min_child_weight = 0.5,\n",
    "    gamma = 0,\n",
    "    subsample = 1,\n",
    "    colsample_bytree = 0.6,\n",
    "    reg_alpha = 0.45,\n",
    "    reg_lambda = 0.2,\n",
    "    learning_rate = 0.05,\n",
    "    n_estimators = 6100,\n",
    "    seed = 42,\n",
    "    nthread = -1,\n",
    "    silent = 1)\n",
    "\n",
    "xgb_regr.fit(x_train, y_train)\n",
    "\n",
    "y_xgb_pred = xgb_regr.predict(x_train)\n",
    "rmse_xgb = rmse(y_train, y_xgb_pred)\n",
    "print(\"XGBoost Regressor score on training set: %f\" % rmse_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test predictions and blending"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the individual model predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ridge_pred = ridge_regr.predict(x_test)\n",
    "y_lasso_pred = lasso_regr.predict(x_test)\n",
    "y_elnet_pred = elnet_regr.predict(x_test)\n",
    "y_rf_pred = rf_regr.predict(x_test)\n",
    "y_svm_pred = svm_regr.predict(x_test)\n",
    "y_xgb_pred = xgb_regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compute the weighted average, using the inverse of the relative training error as the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = 1 / rmse_ridge + 1 / rmse_lasso + 1 / rmse_elnet + 1 / rmse_rf + 1 / rmse_svm + 1 / rmse_xgb \n",
    "\n",
    "y_pred_blend = (y_ridge_pred / rmse_ridge + y_lasso_pred / rmse_lasso + y_elnet_pred / rmse_elnet + \n",
    "                y_rf_pred / rmse_rf + y_svm_pred / rmse_svm + y_xgb_pred / rmse_xgb ) / norm\n",
    "\n",
    "y_pred_blend = np.exp(y_pred_blend) # response was log of SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write prediction to a file, for, e.g., kaggle submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_blend_df = pd.DataFrame(y_pred_blend, index=test_df[\"Id\"], columns=[\"SalePrice\"])\n",
    "pred_blend_df.to_csv('blending_output.csv', header=True, index_label='Id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
