{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactions 111001001 all features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're specifically working on the dataset formed by dropping (31, 496, 524, 917, 1299) with all features.\n",
    "\n",
    "We want to explore whether we can improve our linear models by including interaction terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import optimize\n",
    "\n",
    "pd.set_option('display.precision',20)\n",
    "pd.set_option('display.max_colwidth',100)\n",
    "\n",
    "from sklearn import linear_model, svm, tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, KFold, cross_val_score, \\\n",
    "                                    GridSearchCV, RandomizedSearchCV, ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "    \n",
    "    \n",
    "    \n",
    "import xgboost as xgb\n",
    "\n",
    "from time import time\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "from matplotlib import pyplot\n",
    "rcParams['figure.figsize'] = 12, 4\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def to compare goodness of fit on training set\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run randomized search\n",
    "def random_search(regr, param_dist, n_iter_search): \n",
    "    rs = RandomizedSearchCV(regr, param_distributions=param_dist, scoring = 'neg_mean_squared_error',\n",
    "                                   n_jobs=-1, n_iter=n_iter_search, cv=kfold) #, verbose = 4)\n",
    "    start = time()\n",
    "    rs.fit(x_train, y_train)\n",
    "    print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "    report(rs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run single parameter search (for ridge or lasso)\n",
    "def single_search(regr, params):\n",
    "    regr_results_df = pd.DataFrame(dtype = 'float64')\n",
    "    count = 0\n",
    "    for k, v in params.items():\n",
    "        for val in v:\n",
    "            regr.set_params(**{k: val})\n",
    "            regr_results_df.loc[count, k] = val\n",
    "            results = cross_val_score(regr, x_train, y_train, cv=kfold, scoring = 'neg_mean_squared_error')\n",
    "            (regr_results_df.loc[count, 'RMSE'], regr_results_df.loc[count, 'std dev']) = \\\n",
    "                    (np.sqrt(-results.mean()), np.sqrt(results.std()))\n",
    "            count += 1\n",
    "    return regr_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test against validation set\n",
    "def validate(regr):\n",
    "    regr.fit(x_train, y_train)\n",
    "    y_pred = regr.predict(x_validation)\n",
    "    return rmse(y_validation, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validation sets\n",
    "kfold = KFold(n_splits=10, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./input/train_tidy_111001001.csv\")\n",
    "test_df = pd.read_csv(\"./input/test_tidy_111001001.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ss = ShuffleSplit(n_splits=1, test_size=0.20, random_state=71)\n",
    "\n",
    "X = df.values\n",
    "\n",
    "for train_idx, validation_idx in ss.split(X):\n",
    "    train_df = df.iloc[train_idx]\n",
    "    validation_df = df.iloc[validation_idx]\n",
    "    \n",
    "y_validation = validation_df['SalePrice'].values\n",
    "x_validation = validation_df.drop(['HouseId', 'SalePrice', 'GarageAge', 'GarageAgeLin'],axis=1).values\n",
    "y_train = train_df['SalePrice'].values\n",
    "x_train = train_df.drop(['HouseId', 'SalePrice', 'GarageAge', 'GarageAgeLin'],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 222 iterations, i.e. alpha=3.957e-05, with an active set of 184 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 264 iterations, i.e. alpha=2.193e-05, with an active set of 206 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 265 iterations, alpha=2.182e-05, previous alpha=2.169e-05, with an active set of 206 regressors.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 169 iterations, i.e. alpha=5.659e-05, with an active set of 151 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 184 iterations, i.e. alpha=4.894e-05, with an active set of 160 regressors, and the smallest cholesky pivot element being 1.490e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 195 iterations, i.e. alpha=4.217e-05, with an active set of 169 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 195 iterations, i.e. alpha=4.203e-05, with an active set of 169 regressors, and the smallest cholesky pivot element being 2.220e-16\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 203 iterations, alpha=3.916e-05, previous alpha=3.864e-05, with an active set of 174 regressors.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 269 iterations, i.e. alpha=1.720e-05, with an active set of 211 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 270 iterations, i.e. alpha=1.707e-05, with an active set of 212 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 285 iterations, i.e. alpha=1.350e-05, with an active set of 223 regressors, and the smallest cholesky pivot element being 2.107e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 286 iterations, i.e. alpha=1.314e-05, with an active set of 224 regressors, and the smallest cholesky pivot element being 2.581e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 289 iterations, alpha=1.262e-05, previous alpha=1.261e-05, with an active set of 226 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09813879414399386"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassolarscv_regr = linear_model.LassoLarsCV()\n",
    "baseline = validate(lassolarscv_regr)\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already engineered several features that linearize single features, so we will only focus on generating degree 2 interactions between our features and not powers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree=2, interaction_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures(degree=2, include_bias=True, interaction_only=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58997"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = pf.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_validation = pf.transform(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=1.042e-03, with an active set of 33 regressors, and the smallest cholesky pivot element being 3.495e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 116 iterations, alpha=7.500e-04, previous alpha=7.490e-04, with an active set of 55 regressors.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=7.942e-04, with an active set of 41 regressors, and the smallest cholesky pivot element being 4.470e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=5.965e-04, with an active set of 57 regressors, and the smallest cholesky pivot element being 6.989e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 101 iterations, i.e. alpha=5.614e-04, with an active set of 61 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=5.417e-04, with an active set of 67 regressors, and the smallest cholesky pivot element being 6.664e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=5.277e-04, with an active set of 67 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 114 iterations, alpha=5.237e-04, previous alpha=5.221e-04, with an active set of 65 regressors.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=8.280e-04, with an active set of 43 regressors, and the smallest cholesky pivot element being 3.942e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=7.939e-04, with an active set of 46 regressors, and the smallest cholesky pivot element being 6.664e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=6.309e-04, with an active set of 61 regressors, and the smallest cholesky pivot element being 3.495e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=5.824e-04, with an active set of 61 regressors, and the smallest cholesky pivot element being 4.712e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=5.184e-04, with an active set of 69 regressors, and the smallest cholesky pivot element being 1.054e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=5.171e-04, with an active set of 69 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=5.171e-04, with an active set of 69 regressors, and the smallest cholesky pivot element being 4.593e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 109 iterations, i.e. alpha=5.171e-04, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.788e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:334: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 113 iterations, alpha=5.031e-04, previous alpha=5.027e-04, with an active set of 72 regressors.\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=6.729e-04, with an active set of 45 regressors, and the smallest cholesky pivot element being 3.650e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=5.910e-04, with an active set of 49 regressors, and the smallest cholesky pivot element being 5.674e-08\n",
      "  ConvergenceWarning)\n",
      "/usr/lib64/python2.7/site-packages/sklearn/linear_model/least_angle.py:309: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=5.422e-04, with an active set of 54 regressors, and the smallest cholesky pivot element being 6.144e-08\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (291,343) and (58997,) not aligned: 343 (dim 1) != 58997 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-827039e39549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mintresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlassolarscv_regr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mintresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintresult\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-0be6cdcebbf3>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(regr)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sklearn/linear_model/base.pyc\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[0;32m--> 253\u001b[0;31m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfast_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (291,343) and (58997,) not aligned: 343 (dim 1) != 58997 (dim 0)"
     ]
    }
   ],
   "source": [
    "intresult = validate(lassolarscv_regr)\n",
    "(intresult, intresult - baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10227051672210778, 0.0041317225781139222)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lassolarscv_regr.predict(x_validation)\n",
    "intresult = rmse(y_validation, y_pred)\n",
    "(intresult, intresult - baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x336 x338',\n",
       " 'x336 x339',\n",
       " 'x336 x340',\n",
       " 'x336 x341',\n",
       " 'x336 x342',\n",
       " 'x337 x338',\n",
       " 'x337 x339',\n",
       " 'x337 x340',\n",
       " 'x337 x341',\n",
       " 'x337 x342',\n",
       " 'x338 x339',\n",
       " 'x338 x340',\n",
       " 'x338 x341',\n",
       " 'x338 x342',\n",
       " 'x339 x340',\n",
       " 'x339 x341',\n",
       " 'x339 x342',\n",
       " 'x340 x341',\n",
       " 'x340 x342',\n",
       " 'x341 x342']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.get_feature_names()[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassolarscv_regr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lassolarscv_features = zip(pf.get_feature_names(), lassolarscv_regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lassolars_features_df = pd.DataFrame.from_dict(lassolarscv_features)\n",
    "lassolars_features_df.columns = [\"Feature\", \"Coeff\"]\n",
    "lassolars_features_df = lassolars_features_df[lassolars_features_df[\"Coeff\"]!=0]\n",
    "lassolars_features_df[\"sort_ind\"] = abs(lassolars_features_df[\"Coeff\"])\n",
    "lassolars_features_df = lassolars_features_df.sort_values(by=\"sort_ind\", ascending = False)\n",
    "lassolars_features_df = lassolars_features_df.drop('sort_ind', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25581</th>\n",
       "      <td>x83 x338</td>\n",
       "      <td>0.55775330304807890780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25840</th>\n",
       "      <td>x84 x339</td>\n",
       "      <td>0.52528722903295543833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58497</th>\n",
       "      <td>x310 x339</td>\n",
       "      <td>0.18389808529771745071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58741</th>\n",
       "      <td>x319 x340</td>\n",
       "      <td>0.17648375402997959482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55137</th>\n",
       "      <td>x254 x311</td>\n",
       "      <td>0.16991312963708826711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57867</th>\n",
       "      <td>x294 x341</td>\n",
       "      <td>0.16092994403319466068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39199</th>\n",
       "      <td>x143 x246</td>\n",
       "      <td>-0.15353072233638437316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58434</th>\n",
       "      <td>x308 x341</td>\n",
       "      <td>0.15007783505269023383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25583</th>\n",
       "      <td>x83 x340</td>\n",
       "      <td>0.13305942734290931995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25558</th>\n",
       "      <td>x83 x315</td>\n",
       "      <td>0.10731299088500546868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29653</th>\n",
       "      <td>x100 x160</td>\n",
       "      <td>-0.08904940634670673039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54807</th>\n",
       "      <td>x250 x339</td>\n",
       "      <td>0.08227905935090422396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47037</th>\n",
       "      <td>x187 x318</td>\n",
       "      <td>-0.08186575656869853057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57720</th>\n",
       "      <td>x291 x341</td>\n",
       "      <td>0.07710641068483493898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25544</th>\n",
       "      <td>x83 x301</td>\n",
       "      <td>0.05947598208687181198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57431</th>\n",
       "      <td>x286 x317</td>\n",
       "      <td>0.05826706418182336228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32479</th>\n",
       "      <td>x112 x160</td>\n",
       "      <td>-0.05730018863856829736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57342</th>\n",
       "      <td>x284 x341</td>\n",
       "      <td>0.05364713360052854318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46274</th>\n",
       "      <td>x182 x340</td>\n",
       "      <td>0.05159424164837270177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57399</th>\n",
       "      <td>x285 x341</td>\n",
       "      <td>0.05083592379246471005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55141</th>\n",
       "      <td>x254 x315</td>\n",
       "      <td>0.04182335588807590404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57259</th>\n",
       "      <td>x283 x316</td>\n",
       "      <td>0.03813681487011068294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48759</th>\n",
       "      <td>x199 x258</td>\n",
       "      <td>0.03477258021427869633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43579</th>\n",
       "      <td>x166 x325</td>\n",
       "      <td>0.03279791357587787115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54692</th>\n",
       "      <td>x249 x316</td>\n",
       "      <td>0.03166775002890187540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17847</th>\n",
       "      <td>x55 x234</td>\n",
       "      <td>-0.03083985198885130785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25493</th>\n",
       "      <td>x83 x250</td>\n",
       "      <td>0.02848148354918903641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9153</th>\n",
       "      <td>x26 x269</td>\n",
       "      <td>-0.02790369315022673755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20468</th>\n",
       "      <td>x64 x317</td>\n",
       "      <td>0.02761520187582363478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57752</th>\n",
       "      <td>x292 x323</td>\n",
       "      <td>-0.02757051735332185366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55083</th>\n",
       "      <td>x254 x257</td>\n",
       "      <td>0.02426433009467274596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21881</th>\n",
       "      <td>x70 x83</td>\n",
       "      <td>0.02192788839034564077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46374</th>\n",
       "      <td>x183 x281</td>\n",
       "      <td>0.02065632819667063275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57300</th>\n",
       "      <td>x284 x299</td>\n",
       "      <td>0.01653195987336291209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54884</th>\n",
       "      <td>x251 x325</td>\n",
       "      <td>0.01644386015806660259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25453</th>\n",
       "      <td>x83 x210</td>\n",
       "      <td>0.01548344312318129801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57162</th>\n",
       "      <td>x281 x338</td>\n",
       "      <td>0.01459274379233899653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55507</th>\n",
       "      <td>x258 x339</td>\n",
       "      <td>0.01411705198079733770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37808</th>\n",
       "      <td>x136 x269</td>\n",
       "      <td>-0.01293149633107048939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58067</th>\n",
       "      <td>x299 x316</td>\n",
       "      <td>0.01102081227535033417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20447</th>\n",
       "      <td>x64 x296</td>\n",
       "      <td>0.01033281919617164320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48797</th>\n",
       "      <td>x199 x296</td>\n",
       "      <td>0.00929240534245927632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58433</th>\n",
       "      <td>x308 x340</td>\n",
       "      <td>0.00862215725806036483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46251</th>\n",
       "      <td>x182 x317</td>\n",
       "      <td>0.00712280953826354996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57896</th>\n",
       "      <td>x295 x323</td>\n",
       "      <td>-0.00676160076369911392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>x1 x295</td>\n",
       "      <td>-0.00632453557517215215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35925</th>\n",
       "      <td>x127 x276</td>\n",
       "      <td>-0.00572843973726729072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20234</th>\n",
       "      <td>x64 x83</td>\n",
       "      <td>0.00551406707409684681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55485</th>\n",
       "      <td>x258 x317</td>\n",
       "      <td>0.00399293102937867475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55460</th>\n",
       "      <td>x258 x292</td>\n",
       "      <td>-0.00388239814244439874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54809</th>\n",
       "      <td>x250 x341</td>\n",
       "      <td>0.00369186992844277835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46273</th>\n",
       "      <td>x182 x339</td>\n",
       "      <td>0.00362326832848142415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56976</th>\n",
       "      <td>x278 x338</td>\n",
       "      <td>0.00278136375117168889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42143</th>\n",
       "      <td>x158 x325</td>\n",
       "      <td>0.00266061238695973045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48751</th>\n",
       "      <td>x199 x250</td>\n",
       "      <td>0.00109708905838866010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42972</th>\n",
       "      <td>x163 x249</td>\n",
       "      <td>0.00025557678853314517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Feature                   Coeff\n",
       "25581   x83 x338  0.55775330304807890780\n",
       "25840   x84 x339  0.52528722903295543833\n",
       "58497  x310 x339  0.18389808529771745071\n",
       "58741  x319 x340  0.17648375402997959482\n",
       "55137  x254 x311  0.16991312963708826711\n",
       "57867  x294 x341  0.16092994403319466068\n",
       "39199  x143 x246 -0.15353072233638437316\n",
       "58434  x308 x341  0.15007783505269023383\n",
       "25583   x83 x340  0.13305942734290931995\n",
       "25558   x83 x315  0.10731299088500546868\n",
       "29653  x100 x160 -0.08904940634670673039\n",
       "54807  x250 x339  0.08227905935090422396\n",
       "47037  x187 x318 -0.08186575656869853057\n",
       "57720  x291 x341  0.07710641068483493898\n",
       "25544   x83 x301  0.05947598208687181198\n",
       "57431  x286 x317  0.05826706418182336228\n",
       "32479  x112 x160 -0.05730018863856829736\n",
       "57342  x284 x341  0.05364713360052854318\n",
       "46274  x182 x340  0.05159424164837270177\n",
       "57399  x285 x341  0.05083592379246471005\n",
       "55141  x254 x315  0.04182335588807590404\n",
       "57259  x283 x316  0.03813681487011068294\n",
       "48759  x199 x258  0.03477258021427869633\n",
       "43579  x166 x325  0.03279791357587787115\n",
       "54692  x249 x316  0.03166775002890187540\n",
       "17847   x55 x234 -0.03083985198885130785\n",
       "25493   x83 x250  0.02848148354918903641\n",
       "9153    x26 x269 -0.02790369315022673755\n",
       "20468   x64 x317  0.02761520187582363478\n",
       "57752  x292 x323 -0.02757051735332185366\n",
       "55083  x254 x257  0.02426433009467274596\n",
       "21881    x70 x83  0.02192788839034564077\n",
       "46374  x183 x281  0.02065632819667063275\n",
       "57300  x284 x299  0.01653195987336291209\n",
       "54884  x251 x325  0.01644386015806660259\n",
       "25453   x83 x210  0.01548344312318129801\n",
       "57162  x281 x338  0.01459274379233899653\n",
       "55507  x258 x339  0.01411705198079733770\n",
       "37808  x136 x269 -0.01293149633107048939\n",
       "58067  x299 x316  0.01102081227535033417\n",
       "20447   x64 x296  0.01033281919617164320\n",
       "48797  x199 x296  0.00929240534245927632\n",
       "58433  x308 x340  0.00862215725806036483\n",
       "46251  x182 x317  0.00712280953826354996\n",
       "57896  x295 x323 -0.00676160076369911392\n",
       "979      x1 x295 -0.00632453557517215215\n",
       "35925  x127 x276 -0.00572843973726729072\n",
       "20234    x64 x83  0.00551406707409684681\n",
       "55485  x258 x317  0.00399293102937867475\n",
       "55460  x258 x292 -0.00388239814244439874\n",
       "54809  x250 x341  0.00369186992844277835\n",
       "46273  x182 x339  0.00362326832848142415\n",
       "56976  x278 x338  0.00278136375117168889\n",
       "42143  x158 x325  0.00266061238695973045\n",
       "48751  x199 x250  0.00109708905838866010\n",
       "42972  x163 x249  0.00025557678853314517"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lassolars_features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It appears that only interaction terms were selected in the regression. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
